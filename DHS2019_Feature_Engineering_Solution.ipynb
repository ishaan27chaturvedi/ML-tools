{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## DHS2019 FEATURE ENGINEERING\n",
    "---\n",
    "\n",
    "#### PROBLEM STATEMENT\n",
    "---\n",
    "\n",
    "\n",
    "Email Marketing is still the most successful marketing channel and the essential element of any digital marketing strategy. Marketers spend a lot of time in writing that perfect email, labouring over each word, catchy layouts on multiple devices to get them best in-industry open rates & click rates.\n",
    "\n",
    "How can I build my campaign to increase the click-through rates of email? - a question that is often heard when marketers are creating their email marketing plans.\n",
    "\n",
    "Can we optimize our email marketing campaigns with Data Science?\n",
    "\n",
    "It's time to unlock marketing potential and build some exceptional data-science products for email marketing.\n",
    "\n",
    "Analytics Vidhya sends out marketing emailers for various events such as conferences, hackathons, etc. We have provided a sample of user-email interaction data from July 2017 to December 2017. You are required to predict the click probability of links inside a mailer for email campaigns from January 2018 to March 2018.\n",
    "\n",
    "\n",
    "#### **Contest URL: https://datahack.analyticsvidhya.com/contest/workshop_lord-of-the-machines-data-science-hackath/**\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hOiCKTO7hGWZ"
   },
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn import model_selection, preprocessing, metrics, ensemble\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OlPwccH2hGWj",
    "outputId": "2df5f03b-95f7-451c-c8aa-c189a4d0789c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test shape :  (1023191, 7) (773858, 5)\n"
     ]
    }
   ],
   "source": [
    "# read the datasets\n",
    "train_df = pd.read_csv(\"dataset/train.csv\")\n",
    "test_df = pd.read_csv(\"dataset/test.csv\")\n",
    "campaign_df = pd.read_csv(\"dataset/campaign_data.csv\")\n",
    "\n",
    "# create another column to label train data as 1 and test data as 0\n",
    "train_df[\"train_set\"] = 1\n",
    "test_df[\"train_set\"] = 0\n",
    "print(\"Train and test shape : \", train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>send_date</th>\n",
       "      <th>is_open</th>\n",
       "      <th>is_click</th>\n",
       "      <th>train_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>42_14051</td>\n",
       "      <td>14051</td>\n",
       "      <td>42</td>\n",
       "      <td>01-09-2017 19:55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>52_134438</td>\n",
       "      <td>134438</td>\n",
       "      <td>52</td>\n",
       "      <td>02-11-2017 12:53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>33_181789</td>\n",
       "      <td>181789</td>\n",
       "      <td>33</td>\n",
       "      <td>24-07-2017 15:15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>44_231448</td>\n",
       "      <td>231448</td>\n",
       "      <td>44</td>\n",
       "      <td>05-09-2017 11:36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>29_185580</td>\n",
       "      <td>185580</td>\n",
       "      <td>29</td>\n",
       "      <td>01-07-2017 18:01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  user_id  campaign_id         send_date  is_open  is_click  \\\n",
       "0   42_14051    14051           42  01-09-2017 19:55        0         0   \n",
       "1  52_134438   134438           52  02-11-2017 12:53        0         0   \n",
       "2  33_181789   181789           33  24-07-2017 15:15        0         0   \n",
       "3  44_231448   231448           44  05-09-2017 11:36        0         0   \n",
       "4  29_185580   185580           29  01-07-2017 18:01        0         0   \n",
       "\n",
       "   train_set  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the train data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>send_date</th>\n",
       "      <th>train_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>63_122715</td>\n",
       "      <td>63</td>\n",
       "      <td>122715</td>\n",
       "      <td>01-02-2018 22:35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>56_76206</td>\n",
       "      <td>56</td>\n",
       "      <td>76206</td>\n",
       "      <td>02-01-2018 08:15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>57_96189</td>\n",
       "      <td>57</td>\n",
       "      <td>96189</td>\n",
       "      <td>05-01-2018 18:25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>56_166917</td>\n",
       "      <td>56</td>\n",
       "      <td>166917</td>\n",
       "      <td>02-01-2018 08:15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>56_172838</td>\n",
       "      <td>56</td>\n",
       "      <td>172838</td>\n",
       "      <td>02-01-2018 08:12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  campaign_id  user_id         send_date  train_set\n",
       "0  63_122715           63   122715  01-02-2018 22:35          0\n",
       "1   56_76206           56    76206  02-01-2018 08:15          0\n",
       "2   57_96189           57    96189  05-01-2018 18:25          0\n",
       "3  56_166917           56   166917  02-01-2018 08:15          0\n",
       "4  56_172838           56   172838  02-01-2018 08:12          0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the test data\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>communication_type</th>\n",
       "      <th>total_links</th>\n",
       "      <th>no_of_internal_links</th>\n",
       "      <th>no_of_images</th>\n",
       "      <th>no_of_sections</th>\n",
       "      <th>email_body</th>\n",
       "      <th>subject</th>\n",
       "      <th>email_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>Newsletter</td>\n",
       "      <td>67</td>\n",
       "      <td>61</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>Dear AVians,\\r\\n \\r\\nWe are shaping up a super...</td>\n",
       "      <td>Sneak Peek: A look at the emerging data scienc...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7um44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>Upcoming Events</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear AVians,\\r\\n \\r\\nAre your eager to know wh...</td>\n",
       "      <td>[July] Data Science Expert Meetups &amp; Competiti...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7up0e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>Conference</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Early Bird Pricing Till August 07  Save upto ...</td>\n",
       "      <td>Last chance to convince your boss before the E...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7usym...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   campaign_id communication_type  total_links  no_of_internal_links  \\\n",
       "0           29         Newsletter           67                    61   \n",
       "1           30    Upcoming Events           18                    14   \n",
       "2           31         Conference           15                    13   \n",
       "\n",
       "   no_of_images  no_of_sections  \\\n",
       "0            12               3   \n",
       "1             7               1   \n",
       "2             5               1   \n",
       "\n",
       "                                          email_body  \\\n",
       "0  Dear AVians,\\r\\n \\r\\nWe are shaping up a super...   \n",
       "1  Dear AVians,\\r\\n \\r\\nAre your eager to know wh...   \n",
       "2  Early Bird Pricing Till August 07  Save upto ...   \n",
       "\n",
       "                                             subject  \\\n",
       "0  Sneak Peek: A look at the emerging data scienc...   \n",
       "1  [July] Data Science Expert Meetups & Competiti...   \n",
       "2  Last chance to convince your boss before the E...   \n",
       "\n",
       "                                           email_url  \n",
       "0  http://r.newsletters.analyticsvidhya.com/7um44...  \n",
       "1  http://r.newsletters.analyticsvidhya.com/7up0e...  \n",
       "2  http://r.newsletters.analyticsvidhya.com/7usym...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the campaign data\n",
    "campaign_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert send date to date time format in both train and test data\n",
    "train_df[\"send_date\"] = pd.to_datetime(train_df[\"send_date\"], format=\"%d-%m-%Y %H:%M\")\n",
    "test_df[\"send_date\"] = pd.to_datetime(test_df[\"send_date\"], format=\"%d-%m-%Y %H:%M\")\n",
    "\n",
    "# create new featrure oridnal date \n",
    "# The timestamp returns a long integer containing the number of \n",
    "# seconds between the Unix Epoch (January 1, 1970, 00:00:00 GMT) and the time specified.\n",
    "train_df[\"ordinal_date\"] = train_df[\"send_date\"].apply(lambda x: time.mktime(x.timetuple()))\n",
    "test_df[\"ordinal_date\"] = test_df[\"send_date\"].apply(lambda x: time.mktime(x.timetuple()))\n",
    "\n",
    "# sort the dataframes using oridnal date\n",
    "train_df = train_df.sort_values(by=\"ordinal_date\").reset_index(drop=True)\n",
    "test_df = test_df.sort_values(by=\"ordinal_date\").reset_index(drop=True)\n",
    "\n",
    "# add more features to train and test data by merging it with campaign data  \n",
    "train_df = pd.merge(train_df, campaign_df, on=\"campaign_id\")\n",
    "test_df = pd.merge(test_df, campaign_df, on=\"campaign_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>send_date</th>\n",
       "      <th>is_open</th>\n",
       "      <th>is_click</th>\n",
       "      <th>train_set</th>\n",
       "      <th>ordinal_date</th>\n",
       "      <th>communication_type_x</th>\n",
       "      <th>total_links_x</th>\n",
       "      <th>...</th>\n",
       "      <th>subject_y</th>\n",
       "      <th>email_url_y</th>\n",
       "      <th>communication_type</th>\n",
       "      <th>total_links</th>\n",
       "      <th>no_of_internal_links</th>\n",
       "      <th>no_of_images</th>\n",
       "      <th>no_of_sections</th>\n",
       "      <th>email_body</th>\n",
       "      <th>subject</th>\n",
       "      <th>email_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>29_170634</td>\n",
       "      <td>170634</td>\n",
       "      <td>29</td>\n",
       "      <td>2017-07-01 18:01:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.498912e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>Sneak Peek: A look at the emerging data scienc...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7um44...</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>61</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>Dear AVians,\\r\\n \\r\\nWe are shaping up a super...</td>\n",
       "      <td>Sneak Peek: A look at the emerging data scienc...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7um44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>29_95676</td>\n",
       "      <td>95676</td>\n",
       "      <td>29</td>\n",
       "      <td>2017-07-01 18:01:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.498912e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>Sneak Peek: A look at the emerging data scienc...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7um44...</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>61</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>Dear AVians,\\r\\n \\r\\nWe are shaping up a super...</td>\n",
       "      <td>Sneak Peek: A look at the emerging data scienc...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7um44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29_7740</td>\n",
       "      <td>7740</td>\n",
       "      <td>29</td>\n",
       "      <td>2017-07-01 18:01:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.498912e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>Sneak Peek: A look at the emerging data scienc...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7um44...</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>61</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>Dear AVians,\\r\\n \\r\\nWe are shaping up a super...</td>\n",
       "      <td>Sneak Peek: A look at the emerging data scienc...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7um44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>29_20155</td>\n",
       "      <td>20155</td>\n",
       "      <td>29</td>\n",
       "      <td>2017-07-01 18:01:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.498912e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>Sneak Peek: A look at the emerging data scienc...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7um44...</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>61</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>Dear AVians,\\r\\n \\r\\nWe are shaping up a super...</td>\n",
       "      <td>Sneak Peek: A look at the emerging data scienc...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7um44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>29_134093</td>\n",
       "      <td>134093</td>\n",
       "      <td>29</td>\n",
       "      <td>2017-07-01 18:01:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.498912e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>Sneak Peek: A look at the emerging data scienc...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7um44...</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>61</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>Dear AVians,\\r\\n \\r\\nWe are shaping up a super...</td>\n",
       "      <td>Sneak Peek: A look at the emerging data scienc...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7um44...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  user_id  campaign_id           send_date  is_open  is_click  \\\n",
       "0  29_170634   170634           29 2017-07-01 18:01:00        0         0   \n",
       "1   29_95676    95676           29 2017-07-01 18:01:00        0         0   \n",
       "2    29_7740     7740           29 2017-07-01 18:01:00        0         0   \n",
       "3   29_20155    20155           29 2017-07-01 18:01:00        0         0   \n",
       "4  29_134093   134093           29 2017-07-01 18:01:00        0         0   \n",
       "\n",
       "   train_set  ordinal_date  communication_type_x  total_links_x  ...  \\\n",
       "0          1  1.498912e+09                     3             67  ...   \n",
       "1          1  1.498912e+09                     3             67  ...   \n",
       "2          1  1.498912e+09                     3             67  ...   \n",
       "3          1  1.498912e+09                     3             67  ...   \n",
       "4          1  1.498912e+09                     3             67  ...   \n",
       "\n",
       "                                           subject_y  \\\n",
       "0  Sneak Peek: A look at the emerging data scienc...   \n",
       "1  Sneak Peek: A look at the emerging data scienc...   \n",
       "2  Sneak Peek: A look at the emerging data scienc...   \n",
       "3  Sneak Peek: A look at the emerging data scienc...   \n",
       "4  Sneak Peek: A look at the emerging data scienc...   \n",
       "\n",
       "                                         email_url_y  communication_type  \\\n",
       "0  http://r.newsletters.analyticsvidhya.com/7um44...                   3   \n",
       "1  http://r.newsletters.analyticsvidhya.com/7um44...                   3   \n",
       "2  http://r.newsletters.analyticsvidhya.com/7um44...                   3   \n",
       "3  http://r.newsletters.analyticsvidhya.com/7um44...                   3   \n",
       "4  http://r.newsletters.analyticsvidhya.com/7um44...                   3   \n",
       "\n",
       "  total_links no_of_internal_links no_of_images no_of_sections  \\\n",
       "0          67                   61           12              3   \n",
       "1          67                   61           12              3   \n",
       "2          67                   61           12              3   \n",
       "3          67                   61           12              3   \n",
       "4          67                   61           12              3   \n",
       "\n",
       "                                          email_body  \\\n",
       "0  Dear AVians,\\r\\n \\r\\nWe are shaping up a super...   \n",
       "1  Dear AVians,\\r\\n \\r\\nWe are shaping up a super...   \n",
       "2  Dear AVians,\\r\\n \\r\\nWe are shaping up a super...   \n",
       "3  Dear AVians,\\r\\n \\r\\nWe are shaping up a super...   \n",
       "4  Dear AVians,\\r\\n \\r\\nWe are shaping up a super...   \n",
       "\n",
       "                                             subject  \\\n",
       "0  Sneak Peek: A look at the emerging data scienc...   \n",
       "1  Sneak Peek: A look at the emerging data scienc...   \n",
       "2  Sneak Peek: A look at the emerging data scienc...   \n",
       "3  Sneak Peek: A look at the emerging data scienc...   \n",
       "4  Sneak Peek: A look at the emerging data scienc...   \n",
       "\n",
       "                                           email_url  \n",
       "0  http://r.newsletters.analyticsvidhya.com/7um44...  \n",
       "1  http://r.newsletters.analyticsvidhya.com/7um44...  \n",
       "2  http://r.newsletters.analyticsvidhya.com/7um44...  \n",
       "3  http://r.newsletters.analyticsvidhya.com/7um44...  \n",
       "4  http://r.newsletters.analyticsvidhya.com/7um44...  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label encode the column: [communication_type]\n",
    "for c in [\"communication_type\"]:\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(train_df[c].values.astype('str')) + list(test_df[c].values.astype('str')))\n",
    "    train_df[c] = lbl.transform(list(train_df[c].values.astype('str')))\n",
    "    test_df[c] = lbl.transform(list(test_df[c].values.astype('str')))\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U1LuGs0dhGWr"
   },
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PsZ4glrXhGWt"
   },
   "outputs": [],
   "source": [
    "# define a function to train the lightGBM model\n",
    "def runLGB(train_X, train_y, test_X, test_y=None, test_X2=None): \n",
    "    params = {}\n",
    "    params[\"objective\"] = \"binary\"\n",
    "    params['metric'] = 'auc'\n",
    "    params[\"max_depth\"] = 4\n",
    "    params[\"min_data_in_leaf\"] = 100\n",
    "    params[\"learning_rate\"] = 0.001\n",
    "    params[\"bagging_fraction\"] = 0.7\n",
    "    params[\"feature_fraction\"] = 0.7\n",
    "    params[\"bagging_freq\"] = 5\n",
    "    params[\"bagging_seed\"] = 0\n",
    "    params[\"verbosity\"] = -1\n",
    "    num_rounds = 10000\n",
    "\n",
    "    plst = list(params.items())\n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        lgtest = lgb.Dataset(test_X, label=test_y)\n",
    "        model = lgb.train(params, lgtrain, num_rounds, valid_sets=[lgtest], early_stopping_rounds=100, verbose_eval=50)\n",
    "    else:\n",
    "        lgtest = lgb.DMatrix(test_X)\n",
    "        model = lgb.train(params, lgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "    pred_test_y2 = model.predict(test_X2, num_iteration=model.best_iteration)\n",
    "\n",
    "    loss = 0\n",
    "    if test_y is not None:\n",
    "        loss = metrics.roc_auc_score(test_y, pred_test_y)\n",
    "        print(loss)\n",
    "        return pred_test_y, loss, pred_test_y2\n",
    "    else:\n",
    "        return pred_test_y, loss, pred_test_y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2KxQ33GHhGW0"
   },
   "outputs": [],
   "source": [
    "# filter the columns that you want to use to train the model\n",
    "usecols = [\"user_id\", \"communication_type\", \"total_links\", \"no_of_internal_links\", \"no_of_images\", \"no_of_sections\"]\n",
    "train_X = train_df[usecols]\n",
    "test_X = test_df[usecols]\n",
    "train_y = train_df[\"is_click\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zxb5Wf44hGW5",
    "outputId": "5edb5c9b-6e30-482f-bdee-0b44b2ce9b1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29 35 37 40 43 46 47 54]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.503927\n",
      "[100]\tvalid_0's auc: 0.5043\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.535532\n",
      "0.535532069116465\n",
      "[0.535532069116465]\n",
      "[32 44 45 51 53]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.579146\n",
      "[100]\tvalid_0's auc: 0.579145\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 0.579148\n",
      "0.579147651136752\n",
      "[0.535532069116465, 0.579147651136752]\n",
      "[30 41 48 52]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.501905\n",
      "[100]\tvalid_0's auc: 0.501894\n",
      "[150]\tvalid_0's auc: 0.502117\n",
      "[200]\tvalid_0's auc: 0.502108\n",
      "[250]\tvalid_0's auc: 0.502523\n",
      "[300]\tvalid_0's auc: 0.502825\n",
      "[350]\tvalid_0's auc: 0.502732\n",
      "[400]\tvalid_0's auc: 0.502571\n",
      "Early stopping, best iteration is:\n",
      "[316]\tvalid_0's auc: 0.502826\n",
      "0.5028262333534865\n",
      "[0.535532069116465, 0.579147651136752, 0.5028262333534865]\n",
      "[33 34 39 49]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.495454\n",
      "[100]\tvalid_0's auc: 0.495404\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.496064\n",
      "0.496063919141547\n",
      "[0.535532069116465, 0.579147651136752, 0.5028262333534865, 0.496063919141547]\n",
      "[31 36 38 42 50]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.41014\n",
      "[100]\tvalid_0's auc: 0.410055\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.414545\n",
      "0.41454456808514956\n",
      "[0.535532069116465, 0.579147651136752, 0.5028262333534865, 0.496063919141547, 0.41454456808514956]\n"
     ]
    }
   ],
   "source": [
    "# GroupKFold with n_splits=5\n",
    "cv_scores = []\n",
    "pred_test_full = 0\n",
    "kf = model_selection.GroupKFold(n_splits=5)\n",
    "for dev_index, val_index in kf.split(train_df, train_df[\"is_click\"].values, train_df[\"campaign_id\"].values):\n",
    "    # print the campaign IDs of the current training set\n",
    "    print(train_df[\"campaign_id\"].loc[val_index].unique())\n",
    "    dev_X, val_X = train_X.loc[dev_index,:], train_X.loc[val_index,:]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    # train a lgb model \n",
    "    pred_val, loss, pred_test = runLGB(dev_X, dev_y, val_X, val_y, test_X)\n",
    "    cv_scores.append(loss)\n",
    "    pred_test_full += pred_test\n",
    "    print(cv_scores)\n",
    "pred_test_full /= 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2YMSONozhGW_"
   },
   "outputs": [],
   "source": [
    "# save the calculated results in the csv file and submit it on the contest page to get the results\n",
    "# to create the sample submission file refer to the sample submission file as given on the contest page\n",
    "sub_df = pd.DataFrame({\"id\":test_df[\"id\"].values})\n",
    "sub_df[\"is_click\"] = pred_test_full\n",
    "sub_df.to_csv(\"sub1.csv\", index=False)\n",
    "\n",
    "#### Score is: 0.53"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ptWiQ3PFhGXD"
   },
   "source": [
    "### Check if you can remove some variables and still the model results are similar\n",
    "\n",
    "If you think some of the variables above might be not add much value, then remove them and re-run the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MZP8ieOMhGXE"
   },
   "outputs": [],
   "source": [
    "# filter the columns that you want to use to train the model\n",
    "# ******* EXERCISE 1 **********\n",
    "\n",
    "usecols = [\"user_id\", \"communication_type\"] \n",
    "train_X = train_df[usecols]\n",
    "test_X = test_df[usecols]\n",
    "train_y = train_df[\"is_click\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y0qpx1NshGXJ",
    "outputId": "d3ec56da-29f4-438d-ff56-ce3fb792a07e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29 35 37 40 43 46 47 54]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.54335\n",
      "[100]\tvalid_0's auc: 0.540487\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.543784\n",
      "0.5437840421618861\n",
      "[0.5437840421618861]\n",
      "[32 44 45 51 53]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.593185\n",
      "[100]\tvalid_0's auc: 0.591552\n",
      "[150]\tvalid_0's auc: 0.593148\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.593937\n",
      "0.5939369648958792\n",
      "[0.5437840421618861, 0.5939369648958792]\n",
      "[30 41 48 52]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.495496\n",
      "[100]\tvalid_0's auc: 0.494837\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.503977\n",
      "0.5039767329895155\n",
      "[0.5437840421618861, 0.5939369648958792, 0.5039767329895155]\n",
      "[33 34 39 49]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.49383\n",
      "[100]\tvalid_0's auc: 0.493111\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.498167\n",
      "0.49816658772916067\n",
      "[0.5437840421618861, 0.5939369648958792, 0.5039767329895155, 0.49816658772916067]\n",
      "[31 36 38 42 50]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.594311\n",
      "[100]\tvalid_0's auc: 0.593954\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.594915\n",
      "0.5949150388760787\n",
      "[0.5437840421618861, 0.5939369648958792, 0.5039767329895155, 0.49816658772916067, 0.5949150388760787]\n"
     ]
    }
   ],
   "source": [
    "# GroupKFold with n_splits=5\n",
    "cv_scores = []\n",
    "pred_test_full = 0\n",
    "kf = model_selection.GroupKFold(n_splits=5)\n",
    "for dev_index, val_index in kf.split(train_df, train_df[\"is_click\"].values, train_df[\"campaign_id\"].values):\n",
    "    # print the campaign IDs of the current training set\n",
    "    print(train_df[\"campaign_id\"].loc[val_index].unique())\n",
    "    dev_X, val_X = train_X.loc[dev_index,:], train_X.loc[val_index,:]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    # train a lgb model\n",
    "    pred_val, loss, pred_test = runLGB(dev_X, dev_y, val_X, val_y, test_X)\n",
    "    pred_test_full += pred_test\n",
    "    cv_scores.append(loss)\n",
    "    print(cv_scores)\n",
    "pred_test_full /= 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aRYDQ1MhhGXQ"
   },
   "outputs": [],
   "source": [
    "# submit the results to check the scores\n",
    "sub_df = pd.DataFrame({\"id\":test_df[\"id\"].values})\n",
    "sub_df[\"is_click\"] = pred_test_full\n",
    "sub_df.to_csv(\"sub2.csv\", index=False)\n",
    "\n",
    "## This has reduced the score\n",
    "### Score is: 0.49"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xj4oN83mhGXV"
   },
   "source": [
    "---\n",
    "### Temporal variables \n",
    "\n",
    "Which temporal variables can be created for this problem? Please extract the same and use them to rebuild the models.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SZGVsuiThGXW"
   },
   "outputs": [],
   "source": [
    "# extract a new feature hour from the send_date\n",
    "train_df[\"hour\"] = pd.to_datetime(train_df[\"send_date\"]).dt.hour\n",
    "test_df[\"hour\"] = pd.to_datetime(test_df[\"send_date\"]).dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-Vx4KjAhGXc"
   },
   "outputs": [],
   "source": [
    "# use this new column also and check if it helps to improve the scores\n",
    "usecols = [\"user_id\", \"communication_type\", \"hour\"] \n",
    "train_X = train_df[usecols]\n",
    "test_X = test_df[usecols]\n",
    "train_y = train_df[\"is_click\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4lvACMQKhGXh",
    "outputId": "8607797d-a2e6-415f-a6d5-29dcb1f2d5da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29 35 37 40 43 46 47 54]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.577333\n",
      "[100]\tvalid_0's auc: 0.574894\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.580598\n",
      "0.5805976041918889\n",
      "[0.5805976041918889]\n",
      "[32 44 45 51 53]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.598628\n",
      "[100]\tvalid_0's auc: 0.599174\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.608676\n",
      "0.6086759342199294\n",
      "[0.5805976041918889, 0.6086759342199294]\n",
      "[30 41 48 52]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.494414\n",
      "[100]\tvalid_0's auc: 0.494412\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.494592\n",
      "0.49459173368654896\n",
      "[0.5805976041918889, 0.6086759342199294, 0.49459173368654896]\n",
      "[33 34 39 49]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.514315\n",
      "[100]\tvalid_0's auc: 0.531783\n",
      "[150]\tvalid_0's auc: 0.529677\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's auc: 0.532613\n",
      "0.5326129036133542\n",
      "[0.5805976041918889, 0.6086759342199294, 0.49459173368654896, 0.5326129036133542]\n",
      "[31 36 38 42 50]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.399036\n",
      "[100]\tvalid_0's auc: 0.399278\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.433118\n",
      "0.43311779109057147\n",
      "[0.5805976041918889, 0.6086759342199294, 0.49459173368654896, 0.5326129036133542, 0.43311779109057147]\n"
     ]
    }
   ],
   "source": [
    "# GroupKFold with n_splits=5\n",
    "cv_scores = []\n",
    "kf = model_selection.GroupKFold(n_splits=5)\n",
    "for dev_index, val_index in kf.split(train_df, train_df[\"is_click\"].values, train_df[\"campaign_id\"].values):\n",
    "    # print the campaign IDs of the current training set\n",
    "    print(train_df[\"campaign_id\"].loc[val_index].unique())\n",
    "    dev_X, val_X = train_X.loc[dev_index,:], train_X.loc[val_index,:]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    # train a lgb model\n",
    "    pred_val, loss, pred_test = runLGB(dev_X, dev_y, val_X, val_y, test_X)\n",
    "    cv_scores.append(loss)\n",
    "    print(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y0__SChThGXm"
   },
   "source": [
    "### Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "koHcivFHhGXm"
   },
   "outputs": [],
   "source": [
    "def getDVEncodeVar(compute_df, target_df, var_name, target_var=\"is_click\", min_cutoff=1):\n",
    "    if type(var_name) != type([]):\n",
    "        var_name = [var_name]\n",
    "    grouped_df = target_df.groupby(var_name)[target_var].agg([\"mean\"]).reset_index()\n",
    "    grouped_df.columns = var_name + [\"mean_value\"]\n",
    "    merged_df = pd.merge(compute_df, grouped_df, how=\"left\", on=var_name)\n",
    "    merged_df.fillna(np.mean(target_df[target_var].values), inplace=True)\n",
    "    return list(merged_df[\"mean_value\"])\n",
    "\n",
    "cols_to_use = []\n",
    "kf = model_selection.GroupKFold(n_splits=5)\n",
    "#### columns to target encode \n",
    "# ****** EXERCISE 3*******\n",
    "for col in [[\"user_id\"], [\"user_id\", \"communication_type\"]]:\n",
    "        train_enc_values = np.zeros(train_df.shape[0])\n",
    "        test_enc_values = 0\n",
    "        for dev_index, val_index in kf.split(train_df, train_df[\"is_click\"].values, train_df[\"campaign_id\"].values):\n",
    "            dev_X, val_X = train_df.loc[dev_index], train_df.loc[val_index]\n",
    "            train_enc_values[val_index] = np.array( getDVEncodeVar(val_X[col], dev_X, col, 'is_click'))\n",
    "            test_enc_values += np.array( getDVEncodeVar(test_df[col], dev_X, col, 'is_click'))\n",
    "        test_enc_values /= 5.\n",
    "        if isinstance(col, list):\n",
    "            col = \"_\".join(col)\n",
    "        train_df[col + \"_enc\"] = train_enc_values\n",
    "        test_df[col + \"_enc\"] = test_enc_values\n",
    "        cols_to_use.append(col + \"_enc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TnzKBhOEhGXr",
    "outputId": "9df64365-37d6-4e71-c32e-ae6b51a51623"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'communication_type', 'user_id_enc', 'user_id_communication_type_enc']\n"
     ]
    }
   ],
   "source": [
    "#### EXERCISE 4\n",
    "usecols = [\"user_id\", \"communication_type\"] + cols_to_use\n",
    "print(usecols)\n",
    "train_X = train_df[usecols]\n",
    "test_X = test_df[usecols]\n",
    "train_y = train_df[\"is_click\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anlvetEWhGXx",
    "outputId": "935e165b-b702-4986-debf-aad977493d6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29 35 37 40 43 46 47 54]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.633344\n",
      "[100]\tvalid_0's auc: 0.633874\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.63756\n",
      "0.6375598817669201\n",
      "[0.6375598817669201]\n",
      "[32 44 45 51 53]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.661916\n",
      "[100]\tvalid_0's auc: 0.662224\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.664003\n",
      "0.6640025317157285\n",
      "[0.6375598817669201, 0.6640025317157285]\n",
      "[30 41 48 52]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.611326\n",
      "[100]\tvalid_0's auc: 0.611038\n",
      "[150]\tvalid_0's auc: 0.611964\n",
      "[200]\tvalid_0's auc: 0.610521\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's auc: 0.611994\n",
      "0.6119938319722543\n",
      "[0.6375598817669201, 0.6640025317157285, 0.6119938319722543]\n",
      "[33 34 39 49]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.618856\n",
      "[100]\tvalid_0's auc: 0.620204\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.637937\n",
      "0.6379373391819654\n",
      "[0.6375598817669201, 0.6640025317157285, 0.6119938319722543, 0.6379373391819654]\n",
      "[31 36 38 42 50]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.68315\n",
      "[100]\tvalid_0's auc: 0.685953\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.689828\n",
      "0.6898283514405714\n",
      "[0.6375598817669201, 0.6640025317157285, 0.6119938319722543, 0.6379373391819654, 0.6898283514405714]\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "pred_test_full = 0\n",
    "kf = model_selection.GroupKFold(n_splits=5)\n",
    "for dev_index, val_index in kf.split(train_df, train_df[\"is_click\"].values, train_df[\"campaign_id\"].values):\n",
    "    print(train_df[\"campaign_id\"].loc[val_index].unique())\n",
    "    dev_X, val_X = train_X.loc[dev_index,:], train_X.loc[val_index,:]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    \n",
    "    pred_val, loss, pred_test = runLGB(dev_X, dev_y, val_X, val_y, test_X)\n",
    "    cv_scores.append(loss)\n",
    "    pred_test_full += pred_test\n",
    "    print(cv_scores)\n",
    "pred_test_full /= 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rQ6WcMJLhGX0"
   },
   "outputs": [],
   "source": [
    "# submit the results on the contest page\n",
    "sub_df = pd.DataFrame({\"id\":test_df[\"id\"].values})\n",
    "sub_df[\"is_click\"] = pred_test_full\n",
    "sub_df.to_csv(\"sub3.csv\", index=False)\n",
    "\n",
    "### Score is 0.581"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "27oMZT3ihGX5"
   },
   "source": [
    "### Target encoding with open as target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JGc-ntSIhGX9"
   },
   "outputs": [],
   "source": [
    "cols_to_use = []\n",
    "kf = model_selection.GroupKFold(n_splits=5)\n",
    "#### EXERCISE 5\n",
    "for col in [[\"user_id\"], [\"user_id\", \"communication_type\"]]:\n",
    "        train_enc_values = np.zeros(train_df.shape[0])\n",
    "        test_enc_values = 0\n",
    "        for dev_index, val_index in kf.split(train_df, train_df[\"is_click\"].values, train_df[\"campaign_id\"].values):\n",
    "            dev_X, val_X = train_df.loc[dev_index], train_df.loc[val_index]\n",
    "            train_enc_values[val_index] = np.array( getDVEncodeVar(val_X[col], dev_X, col, 'is_open'))\n",
    "            test_enc_values += np.array( getDVEncodeVar(test_df[col], dev_X, col, 'is_open'))\n",
    "        test_enc_values /= 5.\n",
    "        if isinstance(col, list):\n",
    "            col = \"_\".join(col)\n",
    "        train_df[col + \"_open_enc\"] = train_enc_values\n",
    "        test_df[col + \"_open_enc\"] = test_enc_values\n",
    "        cols_to_use.append(col + \"_open_enc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bWb8H2_WhGYB",
    "outputId": "eb5fdb96-5fa0-4245-af31-0eacf3ea9f51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'communication_type', 'user_id_enc', 'user_id_communication_type_enc', 'user_id_open_enc', 'user_id_communication_type_open_enc']\n"
     ]
    }
   ],
   "source": [
    "#### EXERCISE 6\n",
    "usecols = [\"user_id\", \"communication_type\", 'user_id_enc', 'user_id_communication_type_enc'] + cols_to_use\n",
    "print(usecols)\n",
    "train_X = train_df[usecols]\n",
    "test_X = test_df[usecols]\n",
    "train_y = train_df[\"is_click\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GJHpctHAhGYF",
    "outputId": "357be383-5034-406f-db44-84b4cc6c6aa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29 35 37 40 43 46 47 54]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.700779\n",
      "[100]\tvalid_0's auc: 0.700296\n",
      "[150]\tvalid_0's auc: 0.700404\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's auc: 0.700952\n",
      "0.70095210412181\n",
      "[0.70095210412181]\n",
      "[32 44 45 51 53]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.695309\n",
      "[100]\tvalid_0's auc: 0.695144\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.696679\n",
      "0.696678575834816\n",
      "[0.70095210412181, 0.696678575834816]\n",
      "[30 41 48 52]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.706568\n",
      "[100]\tvalid_0's auc: 0.707789\n",
      "[150]\tvalid_0's auc: 0.707884\n",
      "[200]\tvalid_0's auc: 0.707921\n",
      "[250]\tvalid_0's auc: 0.708038\n",
      "[300]\tvalid_0's auc: 0.708031\n",
      "[350]\tvalid_0's auc: 0.708183\n",
      "[400]\tvalid_0's auc: 0.708186\n",
      "Early stopping, best iteration is:\n",
      "[334]\tvalid_0's auc: 0.708295\n",
      "0.7082953026851153\n",
      "[0.70095210412181, 0.696678575834816, 0.7082953026851153]\n",
      "[33 34 39 49]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.688972\n",
      "[100]\tvalid_0's auc: 0.690303\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.703247\n",
      "0.7032466193944694\n",
      "[0.70095210412181, 0.696678575834816, 0.7082953026851153, 0.7032466193944694]\n",
      "[31 36 38 42 50]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.690841\n",
      "[100]\tvalid_0's auc: 0.691446\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.704808\n",
      "0.7048081223239806\n",
      "[0.70095210412181, 0.696678575834816, 0.7082953026851153, 0.7032466193944694, 0.7048081223239806]\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "pred_test_full = 0\n",
    "kf = model_selection.GroupKFold(n_splits=5)\n",
    "for dev_index, val_index in kf.split(train_df, train_df[\"is_click\"].values, train_df[\"campaign_id\"].values):\n",
    "    print(train_df[\"campaign_id\"].loc[val_index].unique())\n",
    "    dev_X, val_X = train_X.loc[dev_index,:], train_X.loc[val_index,:]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    \n",
    "    pred_val, loss, pred_test = runLGB(dev_X, dev_y, val_X, val_y, test_X)\n",
    "    cv_scores.append(loss)\n",
    "    pred_test_full += pred_test\n",
    "    print(cv_scores)\n",
    "pred_test_full /= 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNI2DCzxhGYI"
   },
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"id\":test_df[\"id\"].values})\n",
    "sub_df[\"is_click\"] = pred_test_full\n",
    "sub_df.to_csv(\"sub4.csv\", index=False)\n",
    "### Score is: 0.666"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_4k_8wSphGYM"
   },
   "source": [
    "### Count for each target encoding variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SKO2PUXehGYN"
   },
   "outputs": [],
   "source": [
    "def getCountVar(compute_df, count_df, var_name, count_var=\"v1\"):\n",
    "    grouped_df = count_df.groupby(var_name)[count_var].agg('count').reset_index()\n",
    "    grouped_df.columns = var_name + [\"var_count\"]\n",
    "\n",
    "    merged_df = pd.merge(compute_df, grouped_df, how=\"left\", on=var_name)\n",
    "    merged_df.fillna(np.mean(grouped_df[\"var_count\"].values), inplace=True)\n",
    "    return list(merged_df[\"var_count\"])\n",
    "\n",
    "cols_to_use = []\n",
    "kf = model_selection.GroupKFold(n_splits=5)\n",
    "#### EXERCISE 7\n",
    "for col in [[\"user_id\"], [\"user_id\", \"communication_type\"]]:\n",
    "        train_enc_values = np.zeros(train_df.shape[0])\n",
    "        test_enc_values = 0\n",
    "        for dev_index, val_index in kf.split(train_df, train_df[\"is_click\"].values, train_df[\"campaign_id\"].values):\n",
    "            dev_X, val_X = train_df.loc[dev_index], train_df.loc[val_index]\n",
    "            train_enc_values[val_index] = np.array( getCountVar(val_X[col], dev_X, col, 'is_open'))\n",
    "            test_enc_values += np.array( getCountVar(test_df[col], dev_X, col, 'is_open'))\n",
    "        test_enc_values /= 5.\n",
    "        if isinstance(col, list):\n",
    "            col = \"_\".join(col)\n",
    "        train_df[col + \"_count\"] = train_enc_values\n",
    "        test_df[col + \"_count\"] = test_enc_values\n",
    "        cols_to_use.append(col + \"_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bw5hJ4d-hGYQ",
    "outputId": "30b99605-6593-4e46-e3f2-29e5256b814a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id_enc', 'user_id_communication_type_enc', 'user_id_open_enc', 'user_id_communication_type_open_enc', 'user_id_count', 'user_id_communication_type_count']\n"
     ]
    }
   ],
   "source": [
    "### EXERCISE 8\n",
    "usecols = ['user_id_enc', 'user_id_communication_type_enc', 'user_id_open_enc', 'user_id_communication_type_open_enc'] + cols_to_use\n",
    "print(usecols)\n",
    "train_X = train_df[usecols]\n",
    "test_X = test_df[usecols]\n",
    "train_y = train_df[\"is_click\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HM2gJtTmhGYU",
    "outputId": "9e6a0d1e-0ed3-4e71-b940-33bf53e240f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29 35 37 40 43 46 47 54]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.700923\n",
      "[100]\tvalid_0's auc: 0.70188\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.702435\n",
      "0.7024346893239648\n",
      "[0.7024346893239648]\n",
      "[32 44 45 51 53]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.698061\n",
      "[100]\tvalid_0's auc: 0.698116\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's auc: 0.699058\n",
      "0.6990579354329693\n",
      "[0.7024346893239648, 0.6990579354329693]\n",
      "[30 41 48 52]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.722059\n",
      "[100]\tvalid_0's auc: 0.72251\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's auc: 0.723146\n",
      "0.723146388239573\n",
      "[0.7024346893239648, 0.6990579354329693, 0.723146388239573]\n",
      "[33 34 39 49]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.722793\n",
      "[100]\tvalid_0's auc: 0.723697\n",
      "[150]\tvalid_0's auc: 0.72353\n",
      "[200]\tvalid_0's auc: 0.724025\n",
      "[250]\tvalid_0's auc: 0.725122\n",
      "[300]\tvalid_0's auc: 0.725045\n",
      "[350]\tvalid_0's auc: 0.7248\n",
      "[400]\tvalid_0's auc: 0.724749\n",
      "Early stopping, best iteration is:\n",
      "[326]\tvalid_0's auc: 0.725296\n",
      "0.7252958029839184\n",
      "[0.7024346893239648, 0.6990579354329693, 0.723146388239573, 0.7252958029839184]\n",
      "[31 36 38 42 50]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.719101\n",
      "[100]\tvalid_0's auc: 0.721446\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 0.721871\n",
      "0.7218713797180698\n",
      "[0.7024346893239648, 0.6990579354329693, 0.723146388239573, 0.7252958029839184, 0.7218713797180698]\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "pred_test_full = 0\n",
    "kf = model_selection.GroupKFold(n_splits=5)\n",
    "for dev_index, val_index in kf.split(train_df, train_df[\"is_click\"].values, train_df[\"campaign_id\"].values):\n",
    "    print(train_df[\"campaign_id\"].loc[val_index].unique())\n",
    "    dev_X, val_X = train_X.loc[dev_index,:], train_X.loc[val_index,:]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    \n",
    "    pred_val, loss, pred_test = runLGB(dev_X, dev_y, val_X, val_y, test_X)\n",
    "    cv_scores.append(loss)\n",
    "    pred_test_full += pred_test\n",
    "    print(cv_scores)\n",
    "pred_test_full /= 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2JpqdYJKhGYX"
   },
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"id\":test_df[\"id\"].values})\n",
    "sub_df[\"is_click\"] = pred_test_full\n",
    "sub_df.to_csv(\"sub5.csv\", index=False)\n",
    "### Score is: 0.6609"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gibsTRzthGYZ"
   },
   "source": [
    "### More Features\n",
    "\n",
    "So far we have created features based on interactions and textbook ideas. Now let us wear the business hat and come up with new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BamB12jDhGYb",
    "outputId": "66f347bf-b7da-404b-a023-da2d2ace979d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lakshay/.local/lib/python3.7/site-packages/pandas/core/frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "#### EXERCISE 9\n",
    "\n",
    "train_df2 = pd.read_csv(\"dataset/train.csv\")\n",
    "test_df2 = pd.read_csv(\"dataset/test.csv\")\n",
    "\n",
    "train_df2[\"send_date\"] = pd.to_datetime(train_df2[\"send_date\"], format=\"%d-%m-%Y %H:%M\")\n",
    "test_df2[\"send_date\"] = pd.to_datetime(test_df2[\"send_date\"], format=\"%d-%m-%Y %H:%M\")\n",
    "\n",
    "train_df2[\"ordinal_date\"] = train_df2[\"send_date\"].apply(lambda x: time.mktime(x.timetuple()))\n",
    "test_df2[\"ordinal_date\"] = test_df2[\"send_date\"].apply(lambda x: time.mktime(x.timetuple()))\n",
    "\n",
    "train_df2 = train_df2.sort_values(by=\"ordinal_date\").reset_index(drop=True)\n",
    "test_df2 = test_df2.sort_values(by=\"ordinal_date\").reset_index(drop=True)\n",
    "\n",
    "## Combine both the datasets \n",
    "full_df = train_df2.append(test_df2).reset_index(drop=True)\n",
    "\n",
    "## User cumulative count\n",
    "full_df[\"user_cum_count\"] = full_df.groupby(\"user_id\")[\"id\"].cumcount()\n",
    "\n",
    "## User count\n",
    "gdf = full_df.groupby(\"user_id\")[\"id\"].size().reset_index()\n",
    "gdf.columns = [\"user_id\", \"user_count\"]\n",
    "full_df = pd.merge(full_df, gdf, on=\"user_id\", how=\"left\")\n",
    "\n",
    "## User previous date diff and camp diff\n",
    "full_df[\"user_prev_date\"] = full_df.groupby(\"user_id\")[\"ordinal_date\"].shift(1)\n",
    "full_df[\"user_prev_camp\"] = full_df.groupby(\"user_id\")[\"campaign_id\"].shift(1)\n",
    "full_df[\"user_date_diff\"] = full_df[\"ordinal_date\"] - full_df[\"user_prev_date\"]\n",
    "full_df[\"user_camp_diff\"] = full_df[\"campaign_id\"] - full_df[\"user_prev_camp\"]\n",
    "\n",
    "## User - camp min, max, mean and std dates\n",
    "gdf = full_df.groupby(\"user_id\")[\"ordinal_date\"].agg([\"min\", \"mean\", \"max\", \"std\"]).reset_index()\n",
    "gdf.columns = [\"user_id\", \"user_min_date\", \"user_mean_date\", \"user_max_date\", \"user_std_date\"]\n",
    "full_df = pd.merge(full_df, gdf, on=\"user_id\")\n",
    "\n",
    "## attended camps\n",
    "pivot_df = pd.pivot_table(full_df, values=\"ordinal_date\", index=\"user_id\", columns=\"campaign_id\", aggfunc=\"count\", fill_value=0).reset_index()\n",
    "pivot_df.columns = [\"user_id\"] + [\"camp_\"+str(i) for i in range(29,81)]\n",
    "full_df = pd.merge(full_df, pivot_df, on=\"user_id\")\n",
    "\n",
    "#train_df = pd.merge(train_df, full_df, on=\"id\", how=\"left\")\n",
    "#test_df = pd.merge(test_df, full_df, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x3T3FOE-hGYe",
    "outputId": "5051a668-86d9-46f3-9f34-272280257f67"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>send_date</th>\n",
       "      <th>is_open</th>\n",
       "      <th>is_click</th>\n",
       "      <th>train_set</th>\n",
       "      <th>ordinal_date</th>\n",
       "      <th>communication_type</th>\n",
       "      <th>total_links</th>\n",
       "      <th>...</th>\n",
       "      <th>camp_71</th>\n",
       "      <th>camp_72</th>\n",
       "      <th>camp_73</th>\n",
       "      <th>camp_74</th>\n",
       "      <th>camp_75</th>\n",
       "      <th>camp_76</th>\n",
       "      <th>camp_77</th>\n",
       "      <th>camp_78</th>\n",
       "      <th>camp_79</th>\n",
       "      <th>camp_80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>29_170634</td>\n",
       "      <td>170634</td>\n",
       "      <td>29</td>\n",
       "      <td>2017-07-01 18:01:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.498912e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>29_7740</td>\n",
       "      <td>7740</td>\n",
       "      <td>29</td>\n",
       "      <td>2017-07-01 18:01:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.498912e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29_20155</td>\n",
       "      <td>20155</td>\n",
       "      <td>29</td>\n",
       "      <td>2017-07-01 18:01:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.498912e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>29_134093</td>\n",
       "      <td>134093</td>\n",
       "      <td>29</td>\n",
       "      <td>2017-07-01 18:01:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.498912e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>29_82171</td>\n",
       "      <td>82171</td>\n",
       "      <td>29</td>\n",
       "      <td>2017-07-01 18:01:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.498912e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  user_id  campaign_id           send_date  is_open  is_click  \\\n",
       "0  29_170634   170634           29 2017-07-01 18:01:00        0         0   \n",
       "1    29_7740     7740           29 2017-07-01 18:01:00        0         0   \n",
       "2   29_20155    20155           29 2017-07-01 18:01:00        0         0   \n",
       "3  29_134093   134093           29 2017-07-01 18:01:00        0         0   \n",
       "4   29_82171    82171           29 2017-07-01 18:01:00        0         0   \n",
       "\n",
       "   train_set  ordinal_date  communication_type  total_links  ...  camp_71  \\\n",
       "0          1  1.498912e+09                   3           67  ...        1   \n",
       "1          1  1.498912e+09                   3           67  ...        0   \n",
       "2          1  1.498912e+09                   3           67  ...        0   \n",
       "3          1  1.498912e+09                   3           67  ...        1   \n",
       "4          1  1.498912e+09                   3           67  ...        0   \n",
       "\n",
       "   camp_72  camp_73 camp_74 camp_75 camp_76  camp_77  camp_78  camp_79  \\\n",
       "0        0        0       1       1       0        0        0        0   \n",
       "1        0        0       0       1       0        0        0        0   \n",
       "2        0        0       0       0       1        0        0        0   \n",
       "3        0        0       1       1       0        0        0        0   \n",
       "4        0        0       0       0       0        0        0        0   \n",
       "\n",
       "   camp_80  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = [\"id\", \"user_cum_count\", \"user_count\", \"user_date_diff\", \"user_camp_diff\", \"user_min_date\", \"user_mean_date\", \"user_max_date\", \"user_std_date\"]\n",
    "fc = fc + [\"camp_\"+str(i) for i in range(29,81)]\n",
    "train_df = pd.merge(train_df, full_df[fc], on=\"id\", how=\"left\")\n",
    "test_df = pd.merge(test_df, full_df[fc], on=\"id\", how=\"left\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GOLnXYpwhGYh",
    "outputId": "ebf25f99-d69a-48b3-9434-c3aaa48c5a7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id_enc', 'user_id_communication_type_enc', 'user_id_open_enc', 'user_id_communication_type_open_enc', 'user_id_count', 'user_id_communication_type_count', 'user_cum_count', 'user_count', 'user_date_diff', 'user_camp_diff', 'user_min_date', 'user_mean_date', 'user_max_date', 'user_std_date', 'camp_29', 'camp_30', 'camp_31', 'camp_32', 'camp_33', 'camp_34', 'camp_35', 'camp_36', 'camp_37', 'camp_38', 'camp_39', 'camp_40', 'camp_41', 'camp_42', 'camp_43', 'camp_44', 'camp_45', 'camp_46', 'camp_47', 'camp_48', 'camp_49', 'camp_50', 'camp_51', 'camp_52', 'camp_53', 'camp_54', 'camp_55', 'camp_56', 'camp_57', 'camp_58', 'camp_59', 'camp_60', 'camp_61', 'camp_62', 'camp_63', 'camp_64', 'camp_65', 'camp_66', 'camp_67', 'camp_68', 'camp_69', 'camp_70', 'camp_71', 'camp_72', 'camp_73', 'camp_74', 'camp_75', 'camp_76', 'camp_77', 'camp_78', 'camp_79', 'camp_80']\n"
     ]
    }
   ],
   "source": [
    "usecols = ['user_id_enc', 'user_id_communication_type_enc', \n",
    "           'user_id_open_enc', 'user_id_communication_type_open_enc',\n",
    "           'user_id_count', 'user_id_communication_type_count'\n",
    "          ]\n",
    "usecols = usecols + [\"user_cum_count\", \"user_count\", \"user_date_diff\", \"user_camp_diff\", \n",
    "                     \"user_min_date\", \"user_mean_date\", \"user_max_date\", \"user_std_date\"]\n",
    "usecols = usecols + [\"camp_\"+str(i) for i in range(29,81)]\n",
    "train_X = train_df[usecols]\n",
    "test_X = test_df[usecols]\n",
    "train_y = train_df[\"is_click\"].values\n",
    "test_id = test_df[\"id\"].values\n",
    "print(usecols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9V2RdPorhGYl",
    "outputId": "0f4a915c-4673-4a62-ef12-a3167105bd82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29 35 37 40 43 46 47 54]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.724284\n",
      "[100]\tvalid_0's auc: 0.727106\n",
      "[150]\tvalid_0's auc: 0.728877\n",
      "[200]\tvalid_0's auc: 0.729128\n",
      "[250]\tvalid_0's auc: 0.729\n",
      "[300]\tvalid_0's auc: 0.728296\n",
      "Early stopping, best iteration is:\n",
      "[213]\tvalid_0's auc: 0.729415\n",
      "0.7294152523130001\n",
      "[0.7294152523130001]\n",
      "[32 44 45 51 53]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.726925\n",
      "[100]\tvalid_0's auc: 0.729549\n",
      "[150]\tvalid_0's auc: 0.728537\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's auc: 0.729634\n",
      "0.7296338112087778\n",
      "[0.7294152523130001, 0.7296338112087778]\n",
      "[30 41 48 52]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.741775\n",
      "[100]\tvalid_0's auc: 0.741272\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.741808\n",
      "0.741807628073808\n",
      "[0.7294152523130001, 0.7296338112087778, 0.741807628073808]\n",
      "[33 34 39 49]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.73452\n",
      "[100]\tvalid_0's auc: 0.736151\n",
      "[150]\tvalid_0's auc: 0.736399\n",
      "[200]\tvalid_0's auc: 0.736612\n",
      "[250]\tvalid_0's auc: 0.736061\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's auc: 0.736705\n",
      "0.7367045836808519\n",
      "[0.7294152523130001, 0.7296338112087778, 0.741807628073808, 0.7367045836808519]\n",
      "[31 36 38 42 50]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's auc: 0.738989\n",
      "[100]\tvalid_0's auc: 0.739309\n",
      "[150]\tvalid_0's auc: 0.740017\n",
      "[200]\tvalid_0's auc: 0.740185\n",
      "[250]\tvalid_0's auc: 0.740084\n",
      "[300]\tvalid_0's auc: 0.740013\n",
      "Early stopping, best iteration is:\n",
      "[221]\tvalid_0's auc: 0.740431\n",
      "0.7404314503209937\n",
      "[0.7294152523130001, 0.7296338112087778, 0.741807628073808, 0.7367045836808519, 0.7404314503209937]\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "pred_test_full = 0\n",
    "kf = model_selection.GroupKFold(n_splits=5)\n",
    "for dev_index, val_index in kf.split(train_df, train_df[\"is_click\"].values, train_df[\"campaign_id\"].values):\n",
    "    print(train_df[\"campaign_id\"].loc[val_index].unique())\n",
    "    dev_X, val_X = train_X.loc[dev_index,:], train_X.loc[val_index,:]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    \n",
    "    pred_val, loss, pred_test = runLGB(dev_X, dev_y, val_X, val_y, test_X)\n",
    "    pred_test_full += pred_test\n",
    "    cv_scores.append(loss)\n",
    "    print(cv_scores)\n",
    "pred_test_full /= 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hn9LKfwUhGYo"
   },
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"id\":test_df[\"id\"].values})\n",
    "sub_df[\"is_click\"] = pred_test_full\n",
    "sub_df.to_csv(\"sub6.csv\", index=False)\n",
    "\n",
    "### Score is: 0.7014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9V4q1PtUhGYr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "DHS2018_FE_Solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
